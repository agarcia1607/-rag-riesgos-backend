#  RAG de AnÃ¡lisis de Riesgos

Sistema de consulta inteligente sobre documentos de riesgos usando arquitectura **Retrieval-Augmented Generation (RAG)** con enfoque baseline-first, robusto y reproducible.

DiseÃ±ado para funcionar **sin dependencias de modelos generativos** y escalar opcionalmente a LLMs, manteniendo control, trazabilidad y estabilidad en producciÃ³n.

---

## ğŸ“‹ Tabla de Contenidos

- [Objetivo](#-objetivo)
- [CaracterÃ­sticas Principales](#-caracterÃ­sticas-principales)
- [Arquitectura](#-arquitectura)
- [Estructura del Proyecto](#-estructura-del-proyecto)
- [InstalaciÃ³n](#-instalaciÃ³n)
- [ConfiguraciÃ³n](#-configuraciÃ³n)
- [Uso](#-uso)
- [Modos de OperaciÃ³n](#-modos-de-operaciÃ³n)
- [API Reference](#-api-reference)
- [Roadmap](#-roadmap)
- [ContribuciÃ³n](#-contribuciÃ³n)

---

##  Objetivo

Permitir consultas en lenguaje natural sobre documentos de riesgos (PDFs), entregando:

-  **Respuestas claras y justificadas** con contexto relevante
-  **Evidencia textual explÃ­cita** con referencias a fuentes
-  **Comportamiento estable** incluso ante fallos de APIs externas
-  **Trazabilidad completa** de cada respuesta generada

Este proyecto prioriza **ingenierÃ­a de sistemas de IA en producciÃ³n**, no solo experimentaciÃ³n.

---

##  CaracterÃ­sticas Principales

###  Arquitectura Resiliente
- **Modo Baseline** (predeterminado): BM25 + extracciÃ³n extractiva sin uso de tokens
- **Modo LLM** (opcional): Gemini + embeddings semÃ¡nticos con fallback automÃ¡tico
- **DegradaciÃ³n elegante**: Si LLM falla, el sistema continÃºa funcionando en modo baseline

###  ProducciÃ³n-Ready
- Zero downtime por cuotas de API
- Respuestas determinÃ­sticas y reproducibles
- Logging estructurado y mÃ©tricas de rendimiento
- Manejo robusto de errores

###  Transparencia
- Fuentes citadas explÃ­citamente
- Scores de relevancia por fragmento
- Metadata de cada respuesta (modo usado, latencia, chunks recuperados)

---

##  Arquitectura
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PDFs   â”‚ â”€â”€â–¶ â”‚ Ingesta â”‚ â”€â”€â–¶ â”‚ Indexing â”‚ â”€â”€â–¶ â”‚ RAG â”‚ â”€â”€â–¶ â”‚ Frontend â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚              â”‚
                                       â–¼              â–¼
                                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                 â”‚   BM25   â”‚   â”‚ Chroma  â”‚
                                 â”‚ Baseline â”‚   â”‚  (LLM)  â”‚
                                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Flujo de Consulta

1. **Usuario** envÃ­a pregunta en lenguaje natural
2. **Query Wrapper** determina modo (baseline/LLM)
3. **Retriever** obtiene chunks relevantes (BM25 o vectorial)
4. **Generator** produce respuesta (extractiva o generativa)
5. **API** devuelve respuesta + fuentes + metadata

---

##  Estructura del Proyecto
```
RAG_riesgos/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py                # FastAPI server + endpoints
â”‚   â”œâ”€â”€ query_wrapper.py       # Orquestador RAG (modo selector)
â”‚   â”œâ”€â”€ baseline_rag.py        # Motor extractivo (BM25)
â”‚   â”œâ”€â”€ baseline_store.py      # Ãndice BM25 + persistencia
â”‚   â”œâ”€â”€ Pdf_loader.py          # Procesamiento y chunking de PDFs
â”‚   â”œâ”€â”€ Vector_store.py        # Embeddings + ChromaDB (modo LLM)
â”‚   â””â”€â”€ config.py              # ConfiguraciÃ³n centralizada
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatInterface.jsx
â”‚   â”‚   â”‚   â””â”€â”€ SourcesPanel.jsx
â”‚   â”‚   â”œâ”€â”€ App.jsx
â”‚   â”‚   â””â”€â”€ index.js
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ Doc chatbot.pdf        # Documento(s) fuente
â”‚
â”œâ”€â”€ chroma_db_riesgos/         # Vector DB (solo modo LLM)
â”œâ”€â”€ baseline_index/            # Ãndice BM25 persistido
â”‚
â”œâ”€â”€ tests/                     # Tests unitarios + integraciÃ³n
â”œâ”€â”€ .env.example
â”œâ”€â”€ .dockerignore
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

##  InstalaciÃ³n

### Prerrequisitos

- Python 3.11+
- Node.js 18+ y npm
- (Opcional) Docker y Docker Compose

### Backend
```bash
# Clonar repositorio
git clone https://github.com/tu-usuario/RAG_riesgos.git
cd RAG_riesgos

# Crear entorno virtual
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate

# Instalar dependencias
pip install -r requirements.txt

# Configurar variables de entorno
cp .env.example .env
# Editar .env con tu configuraciÃ³n
```

### Frontend
```bash
cd frontend
npm install
```

---

##  ConfiguraciÃ³n

### Variables de Entorno (`.env`)
```bash
# Modo de operaciÃ³n (baseline | llm)
RAG_MODE=baseline

# API Keys (solo para modo LLM)
GOOGLE_API_KEY=tu_api_key_aqui

# ConfiguraciÃ³n de chunking
CHUNK_SIZE=500
CHUNK_OVERLAP=50

# ConfiguraciÃ³n de retrieval
TOP_K=5
MIN_SCORE=0.3

# ConfiguraciÃ³n de servidor
BACKEND_PORT=8000
FRONTEND_PORT=3000
```

---

##  Uso

### Iniciar Backend
```bash
# Desarrollo
uvicorn backend.main:app --reload --host 0.0.0.0 --port 8000

# ProducciÃ³n
uvicorn backend.main:app --workers 4 --host 0.0.0.0 --port 8000
```

La API estarÃ¡ disponible en:
- **AplicaciÃ³n**: `http://localhost:8000`
- **DocumentaciÃ³n interactiva**: `http://localhost:8000/docs`
- **OpenAPI Schema**: `http://localhost:8000/openapi.json`

### Iniciar Frontend
```bash
cd frontend
npm start
```

Interfaz disponible en: `http://localhost:3000`

### Docker (Recomendado para ProducciÃ³n)
```bash
# Construir y levantar servicios
docker-compose up --build

# Solo backend
docker-compose up backend

# Detener servicios
docker-compose down
```

---

##  Modos de OperaciÃ³n

###  Modo Baseline (Predeterminado)

**CaracterÃ­sticas:**
- BÃºsqueda lÃ©xica con BM25
- ExtracciÃ³n de frases relevantes
- **Cero consumo de tokens**
- Latencia < 100ms
- 100% reproducible

**CuÃ¡ndo usar:**
- Entornos de producciÃ³n estables
- Cumplimiento regulatorio estricto
- Restricciones de presupuesto
- Documentos tÃ©cnicos/legales donde la cita exacta es crÃ­tica

**ActivaciÃ³n:**
```bash
export RAG_MODE=baseline
```

###  Modo LLM (Opcional)

**CaracterÃ­sticas:**
- Embeddings semÃ¡nticos (Google Gemini)
- BÃºsqueda vectorial con ChromaDB
- Respuestas generativas contextuales
- **Fallback automÃ¡tico** a baseline si hay errores

**CuÃ¡ndo usar:**
- Consultas complejas que requieren sÃ­ntesis
- Usuarios no tÃ©cnicos
- Disponibilidad de presupuesto para APIs

**ActivaciÃ³n:**
```bash
export RAG_MODE=llm
export GOOGLE_API_KEY=tu_api_key
```

**Manejo de Errores:**
```
LLM Request
    â”‚
    â”œâ”€ Success â”€â”€â–¶ Respuesta generativa
    â”‚
    â””â”€ Error (429/Quota/Network)
            â”‚
            â””â”€â”€â–¶ Automatic Fallback â”€â”€â–¶ Baseline Response
```

---

##  API Reference

### `POST /query`

Procesa una consulta en lenguaje natural.

**Request:**
```json
{
  "question": "Â¿CuÃ¡les son los riesgos de liquidez?",
  "mode": "auto"
}
```

**Response:**
```json
{
  "answer": "Los riesgos de liquidez identificados son...",
  "sources": [
    {
      "content": "Fragmento relevante del documento...",
      "page": 5,
      "score": 0.89,
      "metadata": {"document": "Doc chatbot.pdf"}
    }
  ],
  "metadata": {
    "mode_used": "baseline",
    "latency_ms": 87,
    "chunks_retrieved": 5,
    "fallback_triggered": false
  }
}
```

### `POST /ingest`

Procesa nuevos documentos PDF.

**Request:**
```bash
curl -X POST http://localhost:8000/ingest \
  -F "file=@documento.pdf"
```

### `GET /health`

Verifica estado del sistema.

**Response:**
```json
{
  "status": "healthy",
  "mode": "baseline",
  "index_loaded": true,
  "documents_count": 1
}
```

---

##  Roadmap

###  Completado
-  Sistema RAG baseline funcional
-  API REST con FastAPI
-  Frontend React
-  Modo LLM con fallback
-  DocumentaciÃ³n completa

###  En Progreso
-  DockerizaciÃ³n completa
-  Tests de integraciÃ³n (>80% coverage)
-  CI/CD pipeline

###  Futuro
-  Soporte multi-documento (colecciones)
-  Sistema de evaluaciÃ³n automÃ¡tica (RAGAS)
-  Panel administrativo
-  AutenticaciÃ³n y permisos
-  CachÃ© de consultas frecuentes
-  Soporte para mÃ¡s formatos (DOCX, TXT, HTML)
-  IntegraciÃ³n con S3 para almacenamiento
-  MÃ©tricas y observabilidad (Prometheus + Grafana)

---


##  Licencia

[MIT](LICENSE)

---

##  ContribuciÃ³n

Pull requests bienvenidos. Para cambios mayores, por favor abrir un issue primero.
```bash
# Fork y clonar
git checkout -b feature/nueva-funcionalidad
git commit -m "Agrega nueva funcionalidad"
git push origin feature/nueva-funcionalidad
```

---

**Â¿Preguntas?** Abre un issue o contacta al equipo.
